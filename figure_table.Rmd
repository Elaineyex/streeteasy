---
title: "main"
author: "Yanwan Zhu"
date: "3/19/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
# Use the pre-processing script
source("pre-processing.R")
source("text_processing.R")
```


Right now, the pre-processing script has four functions.

```{r sourced functions}

load_data() # creates two dataframes in the global environment

clean_data() # cleans the data

sale_listings_imputed <- impute_data() # imputes size values and returns a new dataframe

#ml_setup sometimes does not work
#ml_setup(sale_listings_imputed) # splits the input data into test and training sets
```

```{r text processing}
#must run pre-processing up to impute_data before text processing
text_var() #create binary variables and sentiment score based on text features
```



```{r check imputation}
original <- ggplot(data=sale_listings_imputed, aes(x=size_sqft))+
  geom_density(color = "blue") +
  geom_vline(xintercept = mean(sale_listings$size_sqft, na.rm = TRUE), color="black", alpha=0.5)

log <- ggplot(data=sale_listings_imputed, aes(x=log(size_sqft)))+
  geom_density(color = "purple") +
  geom_density(aes(x=log(sale_listings$size_sqft)), color = "pink")+
  geom_vline(xintercept = mean(log(sale_listings_imputed$size_sqft)), color="black", alpha=0.5)

library(patchwork)
original / log
```


## Important: things to keep consistent!

- Put all 4 data files in a folder called `data`, because the pre-processing script refers to "data/..."
- `sale-listings`: the variable name for sale-listings
- `amenities`: the variable name for amenities, although we're not using it for now

## Exploratory Data Analysis
- `EDA_text_EY.Rmd`: EDA, data cleaning, bigram visualization

## Models

- `null_naive_ml.R`: null model using the mean price 
- `linear_reg_ml.Rmd`: linear regression models
- `decision_tree_analysis.Rmd`: decision tree and random forest models

## Grouping cities
```{r city_group}
median_price_city <- aggregate(sale_listings_imputed$price, by = list(sale_listings_imputed$major_city), median) %>%
  arrange(desc(x))

median_price_city$price_group <- cut(median_price_city$x, 10, include.lowest=TRUE,
                                     labels = seq(10,1))

city_group <- median_price_city%>%
  select(-x) %>%
  rename(major_city = Group.1,
         city_group = price_group)

sale_listings_imputed <- left_join(sale_listings_imputed, city_group, by ="major_city")
```


## Tables for final paper
### Initial list of variables
\begin{table}[]
\centering
\caption{Variables in the original data set provided by StreetEasy}
\label{intial_var}
\begin{tabular}{ll}
Variable                 & Definition                                 \\
id                       & Unique identifier for sale listing         \\
property\_id             & Unique identifier for property             \\
unittype                 & Property type                              \\
subject                  & Listing subject                            \\
listing\_description     & Listing description                        \\
bedrooms                 & Number of bedrooms                         \\
bathrooms                & Number of bathrooms                        \\
anyrooms                 & Total number of rooms                      \\
size\_sqft               & Square footage                             \\
price                    & Listed price                               \\
addr\_street             & Street                                     \\
addr\_unit               & Unit                                       \\
addr\_cross              & Cross streets                              \\
addr\_hood               & Neighborhood                               \\
addr\_city               & City                                       \\
addr\_state              & State                                      \\
addr\_zip                & Zip code                                   \\
addr\_lon                & Longitude                                  \\
addr\_lat                & Latitude                                   \\
time\_to\_subway         & Time to subway                             \\
half\_baths              & Number of half bath                        \\
census\_tract            & Census tract                               \\
census\_block            & Census block                               \\
building\_count          & Number of building(s)                      \\
floor\_count             & Number of floors in the building           \\
residential\_unit\_count & Number of residential unit in the building \\
total\_unit\_count       & Total number of units in the building      \\
year\_built              & Building year built                        \\
is\_historic             & Whether is a historic building             \\
landmark\_name           & Building landmark name                     \\
area\_name               & Area name                                 
\end{tabular}
\end{table}

### Unit type
```
"NONE         = ' '
CONDO        = 'D'
COOP         = 'P'
TOWNHOUSE    = 'T'
LOFT         = 'L'
CONDOP       = 'N'
HOUSE        = 'H'
MULTIFAMILY  = 'M'
RENTAL       = 'R'
UNKNOWN      = '?'
LAND         = 'A'
COMMERCIAL   = 'C'
MOBILE_HOME  = 'E'
BUILDING     = 'B'
ESTATE       = 'S'
APARTMENT    = 'F' # F is for Flat.
UNCLASSIFIED = 'U'
ANYHOUSE     = 'X'
AUCTION      = 'Z'
FRACTIONAL   = 'Y'"
```
### Sample listing 
```{r}
sample_listing <- sale_listings_ss %>%
  filter(property_id == 9193686)

score_sample <- data.frame(id = c(192, 192, 192, 192, 192, 192, 192),
           word = c("outstanding", "glorious", "beautifully", "tops", "beautifully", "excellent", "glorious"),
           values = c(5, 2, 3, 2, 3, 3, 2))
```



### List of variables after pre-processing & var creation

```{r descriptive stats for numerical var}
descriptive_df <- sentiments_join %>%
  select(price, bedrooms, bathrooms, size_sqft, floor_count, score)
descriptive_num <- psych::describe(descriptive_df) %>%
  select(n, mean, sd, median, min, max)
psychTools::df2latex(descriptive_num)
```

```{r descriptive stats for cat var}
furniture::table1(sale_listings_ss, county, unittype, is_historic, city_group, state, hw_floors, stainless_steel, pet_friendly, wd, steel_app, fitness, marble, master, custom, floor, private, window, dining, offer, sqft, hudson_river, renovate, closet_space, spacious, storage, roof_deck, park, balcony, courtyard, view, natural_light, en_suite, tree_lined, central_park, output = "latex2", na.rm = TRUE)
```

### Summary table for linear regression between word count and sentiment score
\begin{table}[!htbp] \centering 
  \caption{Regression Output of Word Count and Sentiment Score} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{1}{c}{\textit{Dependent variable:}} \\ 
\cline{2-2} 
\\[-1.8ex] & score \\ 
\hline \\[-1.8ex] 
 word\_count & 0.062$^{***}$ \\ 
  & (0.0003) \\ 
  & \\ 
 Constant & 0.519$^{***}$ \\ 
  & (0.063) \\ 
  & \\ 
\hline \\[-1.8ex] 
Observations & 41,325 \\ 
R$^{2}$ & 0.510 \\ 
Adjusted R$^{2}$ & 0.510 \\ 
Residual Std. Error & 7.257 (df = 41323) \\ 
F Statistic & 43,011.900$^{***}$ (df = 1; 41323) \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{1}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table} 

## Visualization 

### Count n. of listings by county 
```{r fig.height=3, fig.width=5}
county_count <- sale_listings_ss %>%
  group_by(county) %>%
  summarize(count = n()) %>%
ggplot(aes(y = fct_reorder(county, count), x=count)) +
  geom_col(fill="#339999") +
  geom_text(aes(label=count), hjust= -0.2, size=3) +
  labs(title = "Number of Listings by County", y = "County") +
  theme_minimal()
```

### Price & sentiment score by county 
```{r}
library(ggridges)
mean_price <- sale_listings_ss %>%
  group_by(county) %>%
  summarise(mean_price = mean(price))

select_county <- sale_listings_ss %>%
  filter(!county %in% c("Nassau County", "Ocean County", "Union County", "Monmouth County", "Essex County")) 
unique(select_county$county)

#Monmouth county only has one entry 
#essex county in NJ only has one entry 
sentiment_p <- ggplot(select_county, aes(x = score, y = fct_reorder(county, score, .fun = mean))) +
  geom_density_ridges(aes(fill = county),quantile_lines=TRUE,
                      quantile_fun=function(x,...)mean(x)) +
  scale_fill_viridis_d() + 
  theme_minimal() + 
  labs(x = "Sentiment Score", 
       y="County", 
       title = "Density Plot of Sentiment Scores by County",
       subtitle = "arranged by mean",
       caption = "Note: only include county with at least 10 listings") +
  theme(legend.position = "none") 
sentiment_p

price_p <- ggplot(select_county, aes(x = price,
       y = fct_reorder(county, price, .fun = mean))) +
  geom_density_ridges(aes(fill = county),quantile_lines=TRUE,
                      quantile_fun=function(x,...)mean(x)) +
  scale_x_continuous(labels = scales::comma) +
  scale_fill_viridis_d() + 
  theme_minimal() +
  labs(x = "Price", 
       y="County", 
       title = "Density Plot of Price by County",
       subtitle = "arranged by mean",
       caption = "Note: only include county with at least 10 listings") +
  theme(legend.position = "none") 
price_p
```



### Single Word Counts 
```{r fig.height=4, fig.width=6}
library(SnowballC)
library(tidytext)

sale_text_tk <- sale_listings_imputed %>%
  unnest_tokens(word, listing_description) %>%
  anti_join(stop_words) 

sale_tk_count <- sale_text_tk %>%
   count(word, sort = TRUE) %>%
  arrange(desc(n))

uni_freq <- sale_tk_count %>%
  head(50) %>%
  ggplot(aes(y=reorder(word,n), x = n)) + 
  geom_bar(stat = "identity", fill="#339999") + 
  labs(title = "Top 50 Frequent Words in Listing Descriptions", x = "Count", y="Word") +
  theme_minimal()
uni_freq

#stemming 
sale_tk_stem <- sale_listings_imputed %>%
  unnest_tokens(word, listing_description) %>%
  anti_join(stop_words) %>%
  mutate(stem = wordStem(word)) 

sale_tk_stem_count <- sale_tk_stem %>%
  count(stem, sort = TRUE) %>%
  arrange(desc(n))

uni_stem_freq <- sale_tk_stem_count %>%
  head(50) %>%
  ggplot(aes(y=reorder(stem,n), x = n)) + 
  geom_bar(stat = "identity")
```

### Bigram Counts 
```{r fig.height=4, fig.width=6}
sale_bigram <- sale_listings_imputed %>%
  unnest_tokens(bigram, listing_description, token = 'ngrams', n=2) %>% 
  separate(bigram, c('word1', 'word2'), sep = " ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>%
  unite(bigram, word1, word2, sep = " ") 

sale_bi_count <- sale_bigram %>%
  count(bigram, sort = TRUE) %>%
  arrange(desc(n))

bi_freq <- sale_bi_count %>%
  head(50) %>%
  ggplot(aes(y=reorder(bigram,n), x = n)) + 
  geom_bar(stat = "identity", fill="#339999") + 
  labs(title = "Top 50 Frequent Bigrams in Listing Descriptions", x = "Count", y="Bigram") +
  theme_minimal()
bi_freq
```



