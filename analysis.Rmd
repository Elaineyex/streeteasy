---
title: "SDS 410"
subtitle: "StreetEasy"
author: "Dayana Meza"
date: "Thursday, March 4th, 2021"
output:
  html_document
---

```{r, include=FALSE}
# Load all packages here
library(ggplot2)
library(lubridate)
library(ical)
library(readr)
library(knitr)
library(tidytext)
library(tm)
library(dplyr)
library(stringr)
library(rpart.plot)
library(SnowballC)
library(tidymodels)
library(slider)
library(future)
library(widyr)
require(furrr)

data(stop_words)

# Load the data 
amenities <- read.csv("amenities.csv", stringsAsFactors = FALSE)
sale <- read.csv("sale_listings.csv", stringsAsFactors = FALSE)

```

# Main Question & Ojectives

## Can we use listing descriptions to predict home prices? 

- Can we convert the description text into meaningful features? 

- Can we use text-based features in addition to the existing features to predict home prices? 

-------------------------------------------------------

<!-- Load Data -->

```{r}
# Datasets 
data <- sale %>% 
  
#Uncomment to merge amenities and sale 
  #merge(sale,amenities,by="property_id") %>% 
  
  # select only descriptions for now
  select(listing_description,price,property_id) 
  
```

<!-- Clean Data -->
  <!-- In this section, we will focus on removing stop words, stemming, and word embedding -->
  <!-- reference: https://smltar.com/stemming.html --> 

```{r}
# Cleaning the Data: Removing Stop Words, Stemming
data <- data %>%
  unnest_tokens(word, listing_description) %>% 
  
  # Remove Stop Words (e.g., "the")
  anti_join(stop_words) %>% 
  
  # Stemming 
  mutate(stem = wordStem(word)) %>% 
  
      # add word count for each stem 
  add_count(stem) %>% 
  
  # Word Embeddings
      #First, letâ€™s filter out words that are used only rarely in this dataset 

  filter(n >= 50) %>%
  select(-n) 
```

```{r}
# Word Embedding 
     # Create a nested dataframe, with one row per word description <!--https://smltar.com/embeddings.html#understand-word-embeddings-by-finding-them-yourself-->

nested_words <- data %>%
  nest(words = c(word))
```

```{r}
# Word Embedding 
slide_windows <- function(tbl, window_size) {
  skipgrams <- slider::slide(
    tbl,
    ~.x,
    .after = window_size - 1,
    .step = 1,
    .complete = TRUE
  )

  safe_mutate <- safely(mutate)

  out <- map2(
    skipgrams,
    1:length(skipgrams),
    ~ safe_mutate(.x, window_id = .y)
  )

  out %>%
    transpose() %>%
    pluck("result") %>%
    compact() %>%
    bind_rows()
}
```


```{r}
# Word Embedding 
  # Takes a lot of processing power, still in the works. 

plan(multiprocess) ## for parallel processing

tidy_pmi <- nested_words %>%
  mutate(words = future_map(words, slide_windows, 4,
    .progress = TRUE
  )) %>%
  unnest(words) %>%
  unite(window_id, property_id, window_id) %>%
  pairwise_pmi(word, window_id)

tidy_pmi
```

<!-- Create Visualization of Frequency of Words --> 
<!--
```{r}
# Get top 5 frequent words
data_freq <- data %>%
  filter(row_number() <= 5)

# Build Viusalization
  # Arrange and make it blue!
ggplot(data = data, aes(x = stem, y = n)) +
  geom_col() 
```

<!-- Build a Classification Model --> 
<!--
```{r}
# 
```

-->